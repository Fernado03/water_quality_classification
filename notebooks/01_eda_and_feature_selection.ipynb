{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc180c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 0. Import Libraries\n",
    "# ======================\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## For Dynamic Pathing ###\n",
    "from pathlib import Path\n",
    "current_dir = Path.cwd()\n",
    "base_dir = current_dir.parent\n",
    "data_path = base_dir / 'data' / 'raw' / 'water_quality.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9daca",
   "metadata": {},
   "source": [
    "## Phase 1: Foundation & Data Acquisition\n",
    "---\n",
    "This notebook covers the initial Exploratory Data Analysis (EDA) for the Water Quality dataset. The key objectives are to understand the data's structure, identify key features for modeling, and check for any data quality issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 1. Create Directories and Load Dataset\n",
    "# ======================\n",
    "\n",
    "# Create directories for saving reports and figures if they don't exist\n",
    "if not os.path.exists('reports/figures'):\n",
    "    os.makedirs('reports/figures')\n",
    "\n",
    "# Load the dataset using a relative path based on the project structure\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"âœ… Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Error: 'data/raw/water_quality.csv' not found.\")\n",
    "    print(\"Please ensure the dataset is in the correct directory.\")\n",
    "    # As a fallback for demonstration, creating a dummy dataframe\n",
    "    df = pd.DataFrame() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 2. Basic Dataset Overview\n",
    "# ======================\n",
    "if not df.empty:\n",
    "    print(\"ðŸ“Š Shape of Dataset:\", df.shape)\n",
    "    print(\"\\nðŸ§¾ Dataset Info:\")\n",
    "    df.info()\n",
    "    print(\"\\nðŸ“ˆ Summary Statistics:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nðŸ“‹ Columns in Dataset:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Explicitly check for missing values\n",
    "    print(\"\\nâ“ Missing Values Check:\")\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a354b57",
   "metadata": {},
   "source": [
    "### **Observation**\n",
    "\n",
    "The initial overview reveals a dataset with **19,029 entries** and **24 columns**. The data types are a mix of `object`, `float64`, and `int64`.\n",
    "\n",
    "The most critical finding from this step is the presence of **missing values**, which contradicts the initial assumption in the project plan. The `isnull().sum()` output shows significant gaps in the following columns:\n",
    "* `Well_ID` (3,785 missing)\n",
    "* `Block` (1,119 missing)\n",
    "* `Latitude` (389 missing)\n",
    "* `Longitude` (390 missing)\n",
    "* `Village` (1 missing)\n",
    "\n",
    "Fortunately, all the core **chemical measurement features** (like `pH`, `EC`, `TDS`, etc.) and the target variable (`Water Quality Classification`) are **complete**, with no missing values.\n",
    "\n",
    "Since the columns with missing data are primarily for location identification and are not planned for use in the model, they can be safely dropped without impacting the core analysis. The `describe()` output also highlights a wide range of values and large standard deviations for many features, suggesting that feature scaling will be crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 3. Identify Feature Types\n",
    "# ======================\n",
    "if not df.empty:\n",
    "    categorical = df.select_dtypes(include='object').columns.tolist()\n",
    "    numerical = df.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "    print(\"\\nðŸ”¢ Numerical Columns:\", numerical)\n",
    "    print(\"ðŸ”  Categorical Columns:\", categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da32f5c",
   "metadata": {},
   "source": [
    "### **Observation**\n",
    "\n",
    "The features are successfully separated into two distinct groups:\n",
    "\n",
    "* **Numerical Columns**: This group contains 18 features, including location data (`Latitude`, `Longitude`), temporal data (`Year`), the Water Quality Index (`WQI`), and all core chemical measurements (`pH`, `EC`, `Cl`, etc.). These will be the primary candidates for correlation analysis and modeling.\n",
    "* **Categorical Columns**: This group includes 6 features, which are mainly location identifiers (`Well_ID`, `State`, `District`, etc.) and the project's target variable, `Water Quality Classification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ca7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 4. Identifier Check\n",
    "# ======================\n",
    "if not df.empty:\n",
    "    print(\"\\nðŸ†” Checking for Identifier Columns...\")\n",
    "    is_identifier_found = False\n",
    "    for col in df.columns:\n",
    "        if df[col].is_unique:\n",
    "            print(f\"'{col}' is likely an identifier column as all its values are unique.\")\n",
    "            is_identifier_found = True\n",
    "    if not is_identifier_found:\n",
    "        print(\"No identifier columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d96eaf",
   "metadata": {},
   "source": [
    "### **Observation**\n",
    "\n",
    "The identifier check reveals that **no column in the dataset contains a unique value for every row**.\n",
    "\n",
    "This is an important finding, as it indicates that even the `Well_ID` column has duplicate entries. This strongly suggests that the dataset contains multiple records for the same wells, likely from samples taken in different years (`2019`, `2020`, `2022`).\n",
    "\n",
    "This confirms that these columns are not suitable as unique row identifiers and validates the decision to exclude them from the feature set for the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36783164",
   "metadata": {},
   "source": [
    "## 5. Correlation and Feature Selection Insight\n",
    "---\n",
    "We analyze the correlation of numerical features with the `Water Quality Index (WQI)`. This helps in identifying the most influential features for predicting water quality, which is crucial for our feature selection process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab670fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 5.1. WQI Correlation Analysis\n",
    "# ======================\n",
    "if 'WQI' in df.columns:\n",
    "    correlation = df.corr(numeric_only=True)\n",
    "    wqi_corr = correlation['WQI'].sort_values(ascending=False)\n",
    "    print(\"\\nðŸ”— Correlation with WQI:\")\n",
    "    print(wqi_corr)\n",
    "\n",
    "    # Heatmap Visualization\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation, annot=True, cmap=\"coolwarm\", fmt='.2f')\n",
    "    plt.title(\"Correlation Heatmap of Water Quality Features\")\n",
    "    \n",
    "    # Save the figure before showing it\n",
    "    plt.savefig('reports/figures/correlation_heatmap.png', bbox_inches='tight')\n",
    "    print(\"\\nâœ… Correlation heatmap saved to 'reports/figures/correlation_heatmap.png'\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ WQI column not found. Please verify dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a5dc6",
   "metadata": {},
   "source": [
    "### **Observation**\n",
    "\n",
    "The correlation analysis provides clear and actionable insights for feature selection. The correlation coefficients with the `Water Quality Index (WQI)` are as follows:\n",
    "\n",
    "* **Extremely High Correlation**:\n",
    "    * `EC` (Electrical Conductivity): **0.98**\n",
    "    * `Cl` (Chloride): **0.93**\n",
    "    * `TDS` (Total Dissolved Solids): **0.92**\n",
    "    * `Na` (Sodium): **0.90**\n",
    "\n",
    "* **Strong Correlation**:\n",
    "    * `TH` (Total Hardness), `Mg` (Magnesium), `SO4` (Sulfate), and `Ca` (Calcium) also show strong positive correlations (ranging from 0.62 to 0.82).\n",
    "\n",
    "* **Negligible Correlation**:\n",
    "    * Features like `pH`, `Year`, `Latitude`, and `Longitude` show almost no linear relationship with the WQI (correlation coefficients are close to zero).\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "This analysis confirms the project plan's hypothesis. The four features with the highest correlation coefficientsâ€”**`EC`**, **`Cl`**, **`TDS`**, and **`Na`**â€”are the most influential predictors of the Water Quality Index. Therefore, these will be the sole features selected for training the final `Water Quality Classification` model. This targeted approach simplifies the model, reduces noise, and improves efficiency without sacrificing predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a166a96",
   "metadata": {},
   "source": [
    " ## 6. Target Variable Analysis\n",
    " ---\n",
    " Here, we examine the distribution of our target variable, `Water Quality Classification`, to understand the class balance. This is critical because a significant imbalance might require special handling techniques like stratified sampling or resampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33348f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 6.1. Target Variable Distribution\n",
    "# ======================\n",
    "if 'Water Quality Classification' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='Water Quality Classification', data=df, palette='viridis', order=df['Water Quality Classification'].value_counts().index)\n",
    "    plt.title('Distribution of Water Quality Classification')\n",
    "    plt.xlabel('Water Quality Classification')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig('reports/figures/target_variable_distribution.png', bbox_inches='tight')\n",
    "    print(\"\\nâœ… Target variable distribution plot saved to 'reports/figures/target_variable_distribution.png'\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Class Balance:\")\n",
    "    print(df['Water Quality Classification'].value_counts())\n",
    "else:\n",
    "    print(\"âš ï¸ 'Water Quality Classification' column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa39f55",
   "metadata": {},
   "source": [
    "### **Observation**\n",
    "\n",
    "The analysis of the target variable, `Water Quality Classification`, reveals a significant **class imbalance** in the dataset.\n",
    "\n",
    "* **Majority Classes**: The dataset is heavily skewed towards lower quality water, with `Unsuitable for Drinking` being the most frequent class (6,567 samples), followed by `Poor` (5,348 samples).\n",
    "\n",
    "* **Minority Classes**: In contrast, higher quality water categories are much less represented. `Good` has only 1,630 samples, and `Excellent` is the rarest class with just 750 samples.\n",
    "\n",
    "**Implication for Modeling:**\n",
    "\n",
    "This imbalance is critical. If we train a model on this data without any adjustments, it will likely become biased towards predicting the majority classes and may struggle to correctly identify the minority classes (`Good` and `Excellent`).\n",
    "\n",
    "To mitigate this, the following steps, as outlined in the project plan, are essential:\n",
    "1.  **Stratified Sampling**: During the train-test split, we must use stratification to ensure that the proportion of each class is identical in both the training and testing sets.\n",
    "2.  **Appropriate Evaluation Metrics**: While accuracy can be misleading, metrics like the **Macro-F1 score** and a detailed **confusion matrix** will be crucial for evaluating the model's performance fairly across all classes, including the underrepresented ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87900f7d",
   "metadata": {},
   "source": [
    " ## 7. Numerical Feature Distribution Analysis\n",
    " ---\n",
    " We will now visualize the distributions of all numerical features to check for skewness and potential outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f551b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "# 7.1. Visualize Numerical Feature Distributions\n",
    "# ======================\n",
    "if not df.empty:\n",
    "    print(\"\\nðŸ“Š Visualizing Numerical Feature Distributions...\")\n",
    "    for col in numerical:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(df[col], kde=True, color='skyblue')\n",
    "        plt.title(f'Histogram of {col}')\n",
    "        \n",
    "        # Box Plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.boxplot(y=df[col], color='lightgreen')\n",
    "        plt.title(f'Box Plot of {col}')\n",
    "        \n",
    "        # Save the combined plot\n",
    "        figure_path = f'reports/figures/distribution_{col}.png'\n",
    "        plt.savefig(figure_path, bbox_inches='tight')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\nâœ… All numerical distribution plots saved to 'reports/figures/'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06651bd8",
   "metadata": {},
   "source": [
    "### **Observation**\n",
    "\n",
    "The visualization of all numerical features reveals a consistent and dominant pattern across the dataset.\n",
    "\n",
    "1.  **Overwhelmingly Right-Skewed Distributions**: With the single exception of `pH`, every chemical measurement feature (`EC`, `Cl`, `TDS`, `Na`, `Ca`, `Mg`, `TH`, `SO4`, `NO3`, `K`, `F`, `CO3`), as well as the `WQI` itself, exhibits a heavily **right-skewed distribution**. The histograms consistently show that the data is concentrated at lower values, with a long tail extending towards higher values. The corresponding box plots for each of these features confirm this pattern, highlighting a significant number of outliers on the higher end. This is a typical characteristic of environmental data where baseline levels are common, but instances of high concentration (potential contamination) are also present.\n",
    "\n",
    "2.  **The Exception: `pH`**: The `pH` feature is the only one that approximates a symmetric, normal distribution, centered around a value of 7-8. Even so, its box plot indicates the presence of outliers on both the lower and upper ends of its scale.\n",
    "\n",
    "3.  **Location and Temporal Data**: The `Latitude` and `Longitude` features are also extremely skewed, containing significant outliers that are likely data entry errors or placeholders. The `Year` feature is discrete, showing the distribution of samples collected in 2019, 2020, and 2022.\n",
    "\n",
    "**Conclusion for Preprocessing:**\n",
    "\n",
    "This comprehensive analysis makes the need for preprocessing even more apparent. The vast differences in scales (e.g., `pH` from ~3-11 vs. `TDS` up to ~17,500) and the severe skewness across nearly all features mandate the use of **feature scaling**.\n",
    "\n",
    "Applying a technique like **Min-Max scaling** during the next phase is an essential step. It will normalize the feature ranges, preventing models from being biased by features with larger magnitudes and ensuring that all selected features contribute fairly to the model's learning process. This will lead to a more robust and reliable classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6283f",
   "metadata": {},
   "source": [
    "---\n",
    "### **End of Phase 1 EDA**\n",
    "*Summary of EDA Findings*\n",
    "\n",
    "The Exploratory Data Analysis has yielded several critical insights that will directly inform the next phases of the project:\n",
    "\n",
    "1.  **Data Quality Issues Identified**: Contrary to the initial project plan, the dataset contains **missing values**. These are concentrated in location-based columns (`Well_ID`, `Block`, `Latitude`, `Longitude`), which are not intended for use in the model. Importantly, all core chemical features and the target variable are complete.\n",
    "\n",
    "2.  **Data-Driven Feature Selection Confirmed**: The correlation analysis successfully validated the feature selection strategy. **Electrical Conductivity (EC)**, **Chloride (Cl)**, **Total Dissolved Solids (TDS)**, and **Sodium (Na)** show the highest correlations (>0.90) with the `Water Quality Index (WQI)`, confirming they are the most impactful predictors.\n",
    "\n",
    "3.  **Severe Class Imbalance Detected**: The target variable, `Water Quality Classification`, is highly imbalanced. The majority of samples are classified as \"Unsuitable for Drinking\" or \"Poor,\" while \"Good\" and \"Excellent\" are significantly underrepresented. This finding makes **stratified sampling** and the use of the **Macro-F1 score** essential for robust modeling and evaluation.\n",
    "\n",
    "4.  **Preprocessing Needs Verified**: The vast majority of numerical features are heavily **right-skewed** and contain numerous high-value outliers. This, along with the wide variance in feature scales, confirms that **feature scaling** (e.g., Min-Max scaling) is a mandatory preprocessing step to ensure model stability and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7875023",
   "metadata": {},
   "source": [
    "In summary, the EDA has provided a clear path forward. The next steps will involve dropping irrelevant columns, handling the identified data characteristics through scaling and stratified sampling, and building a model focused on the four key selected features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
